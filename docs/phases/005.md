

# [PF-060] — OutboxEvent Model, Enums, Envelope + Migration

## Type

Feature

## Description

Introduce the canonical **append-only OutboxEvent model** with locked schema, **authoritative enum definitions**, and a **stable payload envelope** to support versioned, extensible domain events written within DB transactions.

This ticket establishes the foundation all other outbox work depends on.

## Scope

* Create `outbox_events` table via Goose migration
* Define GORM model in `/pkg/db/model`
* Define canonical `event_type` and `aggregate_type` enums
* Define stable JSON payload envelope structs
* Enforce append-only semantics at application level

## Acceptance Criteria

* [ ] `outbox_events` table exists with locked schema and indexes
* [ ] GORM model matches schema exactly
* [ ] Enums are centrally defined and reused (no duplication)
* [ ] Payload envelope structs exist and are documented
* [ ] Only allowed fields are mutable (`published_at`, `attempt_count`, `last_error`)

## Dependencies

* Blocked by: none
* Blocks: PF-061, PF-062

## Technical Notes

**Schema (LOCKED)**

```sql
id              UUID PK
event_type      event_type_enum NOT NULL
aggregate_type  aggregate_type_enum NOT NULL
aggregate_id    UUID NOT NULL
payload_json    JSONB NOT NULL
created_at      TIMESTAMPTZ NOT NULL DEFAULT now()
published_at    TIMESTAMPTZ NULL
attempt_count   INT NOT NULL DEFAULT 0
last_error      TEXT NULL
```

**aggregate_type enums**

* `vendor_order`
* `checkout_group`
* `license`
* `store`
* `media`
* `ledger_event`
* `notification`
* `ad` (business-level lifecycle only)

**event_type enums**
*Core*

* `order_created`
* `order_state_changed`
* `line_item_state_changed`
* `license_status_changed`
* `media_uploaded`
* `payment_settled`
* `cash_collected`
* `vendor_payout_recorded`
* `notification_requested`

*Optional*

* `order_expired`
* `order_canceled`
* `reservation_released`

*Ads (non-telemetry)*

* `ad_created`
* `ad_updated`
* `ad_paused`
* `ad_activated`
* `ad_expired`
* `ad_daily_rollup_ready`

**Indexes**

* `(published_at)`
* `(event_type)`
* `(aggregate_type, aggregate_id)`

**Payload Envelope (LOCKED)**

```go
type OutboxPayloadEnvelope struct {
  Version    int             `json:"version"`
  EventID    string          `json:"eventId"`
  OccurredAt time.Time       `json:"occurredAt"`
  Actor      *ActorRef       `json:"actor,omitempty"`
  Data       json.RawMessage `json:"data"`
}
```

* **ASSUMPTION:** Enums are implemented as Postgres enums (not free-text).
* Add other envelopes that may be relevant, we will add more per ticket later if needed. 

## Out of Scope

* Publishing
* Consumers
* Retention / cleanup
* Telemetry events (clicks, impressions)

---

## [PF-066]: Outbox idempotency strategy (publisher + consumer) using Redis

## Type

Task

## Description

Define and implement the **canonical idempotency strategy** for the Outbox system to safely handle **duplicate publishes and at-least-once delivery**.
This ticket combines publisher-side guarantees and **consumer-side idempotency enforcement**, using Redis as the shared mechanism.

This establishes the **correctness contract** for all async side-effects in PackFinderz.

## Scope

### Included

* Declare the official strategy: **duplicates are allowed; consumers must be idempotent**
* Enforce `event_id` as the **global idempotency key**
* Publisher guarantees:

  * Always include `event_id` in Pub/Sub payload + attributes
  * Structured logging for duplicate visibility
* Consumer guarantees:

  * Shared idempotency helper using Redis
  * Redis key pattern:
    `pf:evt:processed:<consumer_name>:<event_id>`
  * Atomic check-and-set (SETNX)
  * TTL policy for idempotency keys
* Provide a **reference integration example** for one consumer loop

### NOT Included

* Building all consumers (notifications, analytics, media, etc.)
* DLQ / poison message handling
* Exactly-once delivery guarantees
* Persistent audit table (Postgres) — Redis only

## Acceptance Criteria

* [ ] Every published event includes a stable `event_id` (outbox row UUID)
* [ ] Publisher logs include `event_id`, `event_type`, `aggregate_type`, `aggregate_id`
* [ ] Redis helper exposes a single `CheckAndMarkProcessed(...)` API
* [ ] Duplicate deliveries do **not** re-run side-effects
* [ ] Idempotency mechanism is concurrency-safe (SETNX)
* [ ] One consumer example compiles and demonstrates correct usage
* [ ] Strategy is documented clearly: *“duplicates possible; consumers must be idempotent”*

## Dependencies

* Blocked by: PF-061, PF-065
* Blocks: safe rollout of any consumer side effects

## Technical Notes

* **Redis is the source of truth for idempotency**
* Helper location:

  * `pkg/eventing/idempotency` **or**
  * `internal/outbox/idempotency`
* Suggested API:

  ```go
  func CheckAndMarkProcessed(
    ctx context.Context,
    consumer string,
    eventID uuid.UUID,
    ttl time.Duration,
  ) (alreadyProcessed bool, err error)
  ```
* TTL:

  * **ASSUMPTION:** 7–30 days (configurable)
* Redis command:

  * `SET key value NX EX <ttl>`
* Consumers must:

  * Check idempotency **before** side-effects
  * Mark only after successful handling

## Out of Scope

* Consumer business logic
* DLQ
* Persistent idempotency history

---

## [PF-067]: Outbox worker build, local run, and system write-up

## Type

Task

## Description

Finalize the **Outbox publisher worker** as a runnable, operable system by completing build tooling, local execution, and a concise architectural write-up.
This ticket ensures the worker is not just implemented, but **understandable, repeatable, and safe to operate**.

Wire the new `cmd/outbox-publisher` binary into your build and deployment pipeline so it can run alongside API/worker in Heroku (and locally).

Implement the dedicated `cmd/outbox-publisher` binary that continuously polls `outbox_events` for unpublished rows, publishes them to Pub/Sub using a stable message envelope, and marks publish outcomes back in Postgres. This is the bridge between **transactional DB truth** and **async side-effects**.


## Scope

### Included


* Build targets for outbox publisher
* Local run command with env config
* Runtime configuration defaults
* Minimal README / write-up explaining:

  * What the worker does
  * How it claims rows
  * Failure + retry behavior
  * Idempotency expectations
* Documented relationship between:

  * Domain tx → OutboxEvent
  * Publisher → Pub/Sub
  * Consumers → Redis idempotency

  * Makefile targets: build/run publisher locally
  * Dockerfile / heroku.yml updates (as applicable)
  * Procfile (or Heroku dyno command) updates to run `outbox-publisher`
  * Config/env vars for tuning:

    * poll interval
    * batch size
    * max attempts


  * New binary: `cmd/outbox-publisher`
  * DB polling loop for unpublished events (`published_at IS NULL`)
  * Concurrency-safe row claiming (`FOR UPDATE SKIP LOCKED`)
  * Pub/Sub publish (topic mapping per `event_type`)
  * On success: set `published_at`
  * On failure: increment `attempt_count`, set `last_error`
  * Backoff + jitter between loops / on errors
  * Readiness/health wiring consistent with other binaries
  * Minimal infra wiring: Makefile target + Docker/Heroku wiring
  
* **NOT included**

  * DLQ routing
  * Retention cleanup job
  * Consumers/handlers
  * Schema changes


* Terraform/IaC for topics/subscriptions (unless you already track infra that way)
* Consumer implementations
* DLQ or retention jobs

## Acceptance Criteria

* [ ] `make run-outbox-publisher` starts the worker locally
* [ ] Worker runs with zero domain dependencies
* [ ] Configurable batch size, poll interval, max attempts
* [ ] README or `/docs/outbox.md` exists and is accurate
* [ ] Write-up explicitly documents:

  * at-least-once semantics
  * duplicate publish behavior
  * consumer idempotency requirement


* [ ] Worker fetches unpublished rows in batches using `FOR UPDATE SKIP LOCKED` so multiple publishers can run safely
* [ ] Publishing success updates `published_at` for each row only after Pub/Sub publish returns success
* [ ] Publishing failures increment `attempt_count` and set `last_error` (bounded length) without marking `published_at`
* [ ] Worker is restart-safe and does not require manual recovery to continue progress
* [ ] Readiness fails if DB or Pub/Sub dependencies are not ready (consistent with `pkg/*` ready checks)

* [ ] `make run-outbox-publisher` (or equivalent) starts the worker locally
* [ ] Heroku can run the publisher as its own process/dyno
* [ ] Config knobs exist and default safely


## Dependencies

* Blocked by: PF-060 (schema/model/enums/envelope), PF-062 (repo/service APIs)
* Blocks: downstream consumers + reliable async fanout
* Blocked by: PF-061
* Blocks: production rollout + onboarding other devs

## Technical Notes



* Use `outbox.repo.FetchUnpublishedForPublish(limit)` (or equivalent) that:

  * starts a tx
  * selects `published_at IS NULL`
  * `ORDER BY created_at ASC`
  * `FOR UPDATE SKIP LOCKED`
  * returns rows + keeps tx open until rows are claimed (or claim + immediate commit if using a claim marker **NOT allowed** unless added later)
* Publish message should include:

  * `event_id` (outbox id)
  * `event_type`
  * `aggregate_type`, `aggregate_id`
  * `payload_json` (already includes envelope)
  * `created_at`
* Topic mapping:

  * **ASSUMPTION:** single topic `pf-domain-events` with `event_type` attribute for filtering (preferred), unless you already have per-event topics.
* Backoff:

  * base sleep when no rows found (e.g., 250–1000ms)
  * exponential backoff on Pub/Sub errors capped (e.g., 10s)
* Infra:

  * Add `./bin/outbox-publisher` build target
  * Update Heroku dyno command for this worker (separate from general `cmd/worker` if you keep both)



### Suggested env vars

```
PACKFINDERZ_OUTBOX_PUBLISH_BATCH_SIZE=50
PACKFINDERZ_OUTBOX_PUBLISH_POLL_MS=500
PACKFINDERZ_OUTBOX_MAX_ATTEMPTS=10
PACKFINDERZ_OUTBOX_IDEMPOTENCY_TTL_HOURS=168
```

### Write-up must cover

* Why `FOR UPDATE SKIP LOCKED` is used
* Why duplicates are acceptable
* Why Redis is used for idempotency
* Crash scenarios and why they are safe

**ASSUMPTION:** Write-up lives in `/docs/outbox.md` and is referenced by future consumers.

## Out of Scope

* Infra provisioning
* Alerting
* Schema changes















