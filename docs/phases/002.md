## [PF-033] Implement store profile read endpoint (active store)

## Type

Feature

## Description

Implement an authenticated endpoint to fetch the **active store‚Äôs full profile** based on `activeStoreId` from JWT. This endpoint returns **non-public internal fields** and is used for store settings.

## Scope

* Fetch store by `activeStoreId`
* Return full store profile.
* Enforce store-scoped authorization

## Acceptance Criteria

* [ ] `GET /api/v1/stores/me` returns store data for `activeStoreId`
* [ ] Request without `activeStoreId` && valid JWT is rejected
* [ ] Buyer and vendor stores are both supported
* [ ] Response omits any fields not allowed to be read (e.g., internal-only flags if any)

## Dependencies

* Blocked by: Auth + JWT with `activeStoreId`
* Blocks: Store settings UI, store update endpoint

## Technical Notes

* Table: `stores`
* Authorization: store-scoped
* **ASSUMPTION:** Address is returned but not editable in MVP

## Out of Scope

* Public vendor directory fields
* Store analytics data

---

## [PF-034] Implement store profile update endpoint (non-address fields)

## Type

Feature

## Description

Implement an endpoint to update **mutable store fields only** for the active store. Address fields are immutable in MVP and must not be modifiable via this endpoint.

## Scope

* Update allowed store fields (e.g., `description`, `phone`, `email`, `social`, `company_name`, `banner_url`, `logo_url` etc)
* Enforce role-based access (owner/manager only)
* Prevent address or geo changes

## Acceptance Criteria

* [ ] `PUT /api/v1/stores/me` updates allowed fields only
* [ ] Attempt to modify address or geo fields is rejected
* [ ] Only authorized roles may update store
* [ ] Updated timestamps reflect changes

## Dependencies

* Blocked by: [PF-033]
* Blocks: Store settings management

## Technical Notes

* Table: `stores`
* Validation required at API layer
* **ASSUMPTION:** Address mutability handled only via admin override later
* We need to create a new goose migrations to add these fields to a store:  `banner_url` (string), `logo_url` (string), `ratings` (map[string]int), `Categories` (string[])

## Out of Scope

* Admin override of store address
* Subscription or KYC status updates

---

## [PF-035] Implement store user list endpoint

## Type

Feature

## Description

Implement an endpoint to list **all users (memberships)** associated with the active store. Used for store user management.

## Scope

* Fetch memberships for `activeStoreId`
* Include user basic profile + role
* Enforce store-scoped access  (`managers` & `owner` roles can access)

## Acceptance Criteria

* [ ] `GET /api/v1/stores/me/users` returns memberships for active store
* [ ] Only authorized roles can access this endpoint (`managers` & `owner`)
* [ ] Each entry includes user id, email, name (first & last name), role, created_at, last_login_at, member_role, membership_status (pulled from store_member row and may join from User table)

## Dependencies

* Blocked by: Store membership model
* Blocks: Invite/remove user flows

## Technical Notes

* Tables: `store_memberships`, `users`
* **ASSUMPTION:** Pagination optional for MVP due to low cardinality

## Out of Scope

* Cross-store user search
* Role modification (future)

---

## [PF-036]: Implement invite user endpoint (temporary password)

## Type

Feature

## Description

Implement an endpoint to invite a user to the active store by email and role. If the user does not exist, create them with a **temporary password** and add store membership.

## Scope

* Accept email + role
* Create user if not exists
* Create store membership
* Idempotent behavior

## Acceptance Criteria

* [ ] `POST /api/v1/stores/me/users/invite` creates membership
* [ ] Existing users are reused (no duplicate users)
* [ ] Temporary password is generated (not logged) hashed and stored like a normal pass. The user will log in with the pass given and change it in their settings. 
* [ ] Duplicate invite returns idempotent success

## Dependencies

* Blocked by: Users + memberships
* Blocks: Team management

## Technical Notes

* Tables: `users`, `store_memberships`
* **ASSUMPTION:** Temp password is communicated out-of-band
* **ASSUMPTION:** Email sending not implemented yet
* **ASSUMPTION:** Outbox event and notifcation subscriber worker not implemented yet

## Out of Scope

* Email delivery
* Invite acceptance flow

---

## [PF-037]: Implement remove store user endpoint

## Type

Feature

## Description

Implement endpoint to remove a user from the active store by deleting the store membership only.

## Scope

* Delete `store_memberships` row
* Prevent removing last owner
* Enforce authorization

## Acceptance Criteria

* [ ] `DELETE /api/v1/stores/me/users/{userId}` removes membership
* [ ] Removing last owner is rejected
* [ ] User account itself is not deleted

## Dependencies

* Blocked by: [PF-035]
* Blocks: Store user management completeness

## Technical Notes

* Table: `store_memberships`
* **ASSUMPTION:** Last-owner constraint enforced at API layer

## Out of Scope

* Deleting users globally
* Role reassignment

---

Here is the **single consolidated ticket** for **Phase 2 ‚Äî Media Metadata Persistence (Postgres)**, written **exactly in the style and rigor of your example**.

---

## [PF-038]: Implement canonical `Media` metadata persistence (Postgres + GORM)

## Type

Task

## Description

Implement the canonical **Media metadata persistence layer** for PackFinderz. This includes authoritative Postgres tables for uploaded media objects and their attachments to domain entities. All media metadata MUST be stored in Postgres via Goose SQL migrations and mapped via GORM models. This phase establishes the database and repository foundation for all GCS-backed uploads (licenses, COAs, manifests, product media, ads, profile pictures, etc).

This ticket does **not** implement upload or presigned URL flows; it strictly defines the metadata layer used by those flows.

## Scope

* Implement Goose SQL migration to create `media` table (per Data Design)
* Define canonical `media_kind` enum values
* Implement GORM models for `Media`
* Implement base media repository with create, fetch, delete, and attach semantics

## Acceptance Criteria

* [ ] Goose migration creates `media` table with:

  * `id` (uuid, pk)
  * `store_id` (uuid, not null)
  * `user_id` (uuid, not null)
  * `kind` (`media_kind` enum)
  * `gcs_key` (text unique) // This is the key to reference the GCS object
  * `file_name` (text)
  * `mime_type` (text)
  * `ocr` (text nullable) // the OCR text file reference if avaialble
  * `size_bytes` (bigint)
  * `is_compressed` (boolean, default false)
  * `created_at` (timestamptz)

* [ ] Canonical `media_kind` enum includes:

  * `product` (product images, profile/store images, ads)
  * `ads` (product videos, ad creatives)
  * `pdf`
  * `license_doc`
  * `coa`
  * `manifest`
  * `user`
  * `other`
* [ ] GORM models exist for `Media` in the DB models folder
* [ ] Base media repository supports:

  * create media record
  * fetch media by ID
  * delete media (later ticket will also delete the GSC instance)
* [ ] No storage URLs or secrets are derived or mutated in this layer

## Dependencies

* Blocked by: Phase 0 infra (Postgres + Goose runner)
* Blocks:

  * Presigned upload flow
  * Media finalize endpoint
  * License upload
  * Product / ad media attachments
  * Manifest storage

## Technical Notes

* Tables: `media`
* Enums: `media_kind` (Postgres enum)
* Ownership:

  * `media.store_id` is optional but preferred for store-scoped uploads
  * `media.user_id` tracks uploader when available
* Repository MUST accept injected `*gorm.DB` and be context-aware
* **ASSUMPTION:** Hard deletes are allowed only when no attachments exist

## Out of Scope

* GCS client setup
* Presigned upload or download URLs
* Media compression or OCR
* Background processing workers
* Public vs private media access rules

---

## [PF-039]: Bootstrap Google Cloud Storage (GCS) client for API and worker

## Type

Task

## Description

Implement a **canonical, reusable Google Cloud Storage (GCS) client bootstrap** for PackFinderz and wire it into both the API and worker binaries. GCS must be treated as a first-class infrastructure dependency, similar to `pkg/db` and `pkg/redis`.

The GCS client MUST live under `pkg/storage` (with sub-packages as needed) and support **context-aware injection**, **multiple authentication strategies**, and **multi-bucket usage**. Both `cmd/api` and `cmd/worker` MUST initialize and reuse the same client abstraction. Readiness probes MUST fail if GCS is unavailable or misconfigured.

## Scope

* Implement canonical GCS client bootstrap under `pkg/storage`
* Support authentication via:

  * Service account JSON (from env / file)
  * Default credentials / IAM permissions (gcloud / workload identity)
* Read bucket configuration from env (per existing ENV file)
  ```env
    PACKFINDERZ_GCS_BUCKET_NAME=packfinderz-media
    PACKFINDERZ_GCS_UPLOAD_URL_EXPIRY=15m
    PACKFINDERZ_GCS_DOWNLOAD_URL_EXPIRY=30m
  ```
* Wire GCS client initialization into:

  * `cmd/api` startup
  * `cmd/worker` startup
* Register GCS as a required dependency in health/readiness checks

## Acceptance Criteria

* [x] A `pkg/storage/gcs` package exists with:

  * Context-aware client creation
  * Clean public interface (no direct usage of `storage.NewClient` outside this package)
* [x] GCS client supports **both** auth modes:

  * Service account JSON credentials (explicit)
  * Implicit credentials via gcloud / IAM
* [x] Bucket names are injected via env vars from the config files in pkg (no hardcoded bucket names)
* [x] API binary initializes GCS client during startup and fails fast on error
* [x] Worker binary initializes GCS client during startup and fails fast on error
* [x] GCS dependency is included in `/health/ready` checks
* [x] No credentials, bucket names, or object paths are logged
* [x] GCS client is shared via dependency injection (not recreated per request)

* **Implementation:** new `pkg/storage/gcs` bootstrap + `NewClient`, API/worker initialization, `/health/ready` dependency check, and shared routing.

## Dependencies

* Blocked by: Phase 0 infra (GCP project, buckets, IAM permissions)
* Blocks:

  * Media presigned upload
  * Media finalize flow
  * License / COA / manifest / Media (pic/video) storage
  * Media processing worker

## Technical Notes

* Package structure (suggested):

  ```
  pkg/
    storage/
      client.go        // client bootstrap + options
      buckets.go       // typed bucket handles (from config + constants file from pkg)
      health.go        // readiness checks (used in the health api)
      errors.go        // wrapped, typed errors (use the pkg/errors though)
  ```

* Auth strategy:

  * If explicit service account JSON env var is present ‚Üí use it
  * Else fall back to default credentials (gcloud / workload identity)

* Client MUST accept `context.Context`
* GCS client MUST be created once at startup and reused
* Health check MAY perform a lightweight operation (e.g. bucket attrs)
* **ASSUMPTION:** Bucket names are already defined in env
* Probably need to use `cloud.google.com/go/storage`


## Out of Scope

* Presigned upload/download URLs
* Media metadata persistence
* Object lifecycle rules
* Public vs private bucket policy
* Media compression / OCR

---

Here‚Äôs the **single consolidated ticket** for **Phase 3 ‚Äî Presigned Upload Flow (Client ‚Üí GCS)**, written to **match your example exactly**, and explicitly **building on the fact that the GCS client already exists** and `media_kind` enums are already defined.

---
Perfect ‚Äî based on your **final answers + existing commits (PF-038, PF-039)**, here is a **clean, dependency-ordered backend-only ticket list**, following **your exact lifecycle**, **no finalize endpoint**, **Pub/Sub‚Äìdriven verification**, and **combined where it makes sense**.

I am **not** inventing frontend work, and I‚Äôm explicitly aligning with your state diagram + sequence diagram.

---

# üì¶ Media + Upload System ‚Äî Remaining Backend Tickets

---

## üü¢ Already Completed (for context)

* ‚úÖ **PF-038** ‚Äî Canonical metadata persistence (licenses groundwork)
* ‚úÖ **PF-039** ‚Äî Bootstrap GCS client for API + worker

Everything below assumes those exist.

---

## [PF-040] Create `media` table + enum + GORM model (upload lifecycle)

## Type

Feature

## Description

Modify the canonical `media` persistence model that tracks uploaded objects across the platform, including lifecycle state, ownership, and metadata. This table is the **source of truth** for all uploaded files and their processing state.

## Scope

* Create `media_status` enum
* Create `media` table with lifecycle fields + timestamps
* Modify GORM `Media` model aligned with schema
* Add if not present indexes and constraints for idempotency and lookup

## Acceptance Criteria

* [ ] Postgres enum `media_status` exists with values:
  `pending | uploaded | processing | ready | failed | delete_requested | deleted | delete_failed`
* [ ] `media` table exists with:

  * `id uuid pk`
  * `store_id uuid not null`
  * `user_id uuid not null`
  * `kind media_kind not null`
  * `status media_status not null default 'pending'`
  * `gcs_key text not null unique`
  * `file_name text not null`
  * `mime_type text not null`
  * `size_bytes bigint not null`
  * `ocr text null`
  * `is_compressed boolean not null default false`
  * timestamps:
    `created_at`, `updated_at`,
    `uploaded_at`, `verified_at`,
    `processing_started_at`, `ready_at`,
    `failed_at`, `deleted_at`
* [ ] Indexes:

  * `unique(gcs_key)`
  * `(store_id, created_at desc)`
* [ ] GORM model matches schema exactly
* [ ] Goose migration is reversible

## Dependencies

* Blocked by: DB bootstrap
* Blocks: presign endpoint, workers, media reads

## Technical Notes

* `gcs_key` format:
  `<STORE_ID>/<MEDIA_KIND>/<MEDIA_ID>.<ext>`
* Bucket name is **not stored** (env-level concern)

## Out of Scope

* Upload endpoints
* Signed URLs
* Workers

---

## [PF-041] Implement `POST /api/v1/media/presign` (create media row + signed PUT)

## Type

Feature

## Description

Allow authenticated users to initiate uploads by generating a signed GCS PUT URL. This endpoint **creates the media row first**, assigns a deterministic GCS object key, and returns a signed URL for direct client upload.

This is the **only API call required before upload**.

## Scope

* Endpoint: `POST /api/v1/media/presign`
* Validate:

  * auth + activeStoreId
  * role permissions
  * media_kind
  * mime_type
  * size_bytes ‚â§ 20MB
* Generate:

  * `media_id`
  * `gcs_key`
* Insert `media` row with `status = pending`
* Generate signed PUT URL with:

  * exact `Content-Type` enforcement
  * short TTL
* Enforce idempotency via `Idempotency-Key`

## Acceptance Criteria

* [ ] Media row is created **before** upload begins
* [ ] Same idempotency key returns same `{media_id, gcs_key, signed_put_url}`
* [ ] `gcs_key` always includes `media_id`
* [ ] Signed PUT requires matching `Content-Type`
* [ ] No upload proxying through API
* [ ] Logs never include signed URLs or raw GCS keys

## Dependencies

* Blocked by: PF-040, PF-039
* Blocks: upload completion via Pub/Sub

## Technical Notes

* Allowed mime mapping derived from `media_kind` enum
* Max size: **20MB global**
* No checksum support (explicit)

## Out of Scope

* Multipart uploads
* Resumable uploads
* Media processing

---

## [PF-042] Pub/Sub worker: handle GCS `OBJECT_FINALIZE` ‚Üí mark media uploaded

## Type

Feature

## Description

Subscribe to GCS `OBJECT_FINALIZE` events via Pub/Sub and transition media rows from `pending` ‚Üí `uploaded`. This replaces any client-side ‚Äúfinalize‚Äù endpoint.

## Scope

* Subscribe worker to GCS notifications Pub/Sub topic
* Parse event payload
* Lookup media row by `gcs_key`
* Deduplicate events
* Update media state and timestamps

## Acceptance Criteria

* [ ] Worker consumes `OBJECT_FINALIZE` events
* [ ] Media row found by `gcs_key`
* [ ] Status transitions:

  * `pending ‚Üí uploaded`
  * `uploaded_at`, `verified_at` set
* [ ] Duplicate events are ignored safely
* [ ] Unknown keys do not crash worker

## Dependencies

* Blocked by: PF-040
* Blocks: processing pipeline, signed reads

## Technical Notes

* **Deduplication required**:

  * Use `(gcs_key + generation)` stored in Redis or DB
* Event source: GCS ‚Üí Pub/Sub (not Eventarc)

## Out of Scope

* OCR / compression
* Processing logic
* Deletion

---

## [PF-043] Media processing stub worker (uploaded ‚Üí ready)

## Type

Task

## Description

Stub the media processing pipeline so uploaded media flows cleanly through lifecycle states even before OCR/compression exists.

## Scope

* When media transitions to `uploaded`:

  * Set `processing`
  * Immediately set `ready`
* Populate processing timestamps

## Acceptance Criteria

* [ ] Media transitions:
  `uploaded ‚Üí processing ‚Üí ready`
* [ ] `processing_started_at` and `ready_at` are set
* [ ] Failures move media to `failed`

## Dependencies

* Blocked by: PF-042
* Blocks: licenses, products, ads media usage

## Technical Notes

* Placeholder logic only
* Future OCR/compression will replace this

## Out of Scope

* Actual OCR
* Actual compression

---

## [PF-044] Signed READ URL resolution for media (API helper + endpoint)

## Type

Feature

## Description

Generate short-lived signed READ URLs for private media at request time. URLs are **never persisted** and are generated only when needed.

## Scope

* Add media read service:

  * Resolve signed GET URL from `gcs_key`
* Endpoint:

  * `GET /api/v1/media/{mediaId}`
* Enforce store ownership
* TTL configurable via env

## Acceptance Criteria

* [ ] Signed READ URL generated on demand
* [ ] URL is short-lived
* [ ] Store scoping enforced (404-safe)
* [ ] Missing GCS objects are omitted gracefully
* [ ] No signed URLs logged

## Dependencies

* Blocked by: PF-040, PF-039
* Blocks: licenses, products, ads

## Technical Notes

* Uses same GCS client as presign
* Private bucket only (public buckets later)

## Out of Scope

* CDN caching
* Public assets
* Batch reads

---

## [PF-045] Media deletion flow (API + worker)

## Type

Feature

## Description

Implement safe media deletion via lifecycle state changes and background workers.

## Scope

* API endpoint:

  * `DELETE /api/v1/media/{mediaId}`
* API behavior:

  * Validate ownership
  * Set `status = delete_requested`
  * Emit outbox event
* Worker:

  * Delete GCS object
  * Update DB status + timestamps

## Acceptance Criteria

* [ ] Media marked `delete_requested` via API
* [ ] Worker deletes GCS object
* [ ] DB updated to `deleted` or `delete_failed`
* [ ] Idempotent deletes do not error

## Dependencies

* Blocked by: PF-040
* Blocks: cleanup, future attachment enforcement

## Technical Notes

* Orphan protection intentionally skipped (documented)
* Missing objects handled gracefully

## Out of Scope

* Attachment enforcement
* Cascade deletes

---

## [PF-XXX]: Implement license metadata creation endpoint

## Type

Feature

## Description

Create an endpoint to create a **license metadata record** in `pending` state before document upload is finalized.

## Scope

* Create license row with metadata
* Associate license with active store
* Idempotent behavior

## Acceptance Criteria

* [ ] `POST /api/v1/licenses` creates license with `pending` status
* [ ] License belongs to `activeStoreId`
* [ ] Duplicate submission with same idempotency key replays response

## Dependencies

* Blocked by: Stores, auth
* Blocks: License upload + verification

## Technical Notes

* Table: `licenses`
* **ASSUMPTION:** Media attachment added later via finalize endpoint

## Out of Scope

* Document upload
* Verification logic

---

## [PF-039] Implement GCS presigned upload helper + endpoint (licenses)

## Type

Infra

## Description

Implement a reusable **GCS client helper** and an endpoint to generate presigned upload URLs for license documents.

## Scope

* GCS client in `pkg/storage` (or equivalent)
* Presigned URL generation
* Endpoint for license uploads

## Acceptance Criteria

* [ ] GCS helper initializes using service credentials
* [ ] `POST /api/v1/media/presign` returns valid signed URL
* [ ] URL is time-limited and upload-only

## Dependencies

* Blocked by: GCS credentials/config
* Blocks: License document upload

## Technical Notes

* Service: Google Cloud Storage
* **ASSUMPTION:** Same helper reused for all media types later

## Out of Scope

* Media finalization
* Background processing

---

## [PF-040] Implement license finalize endpoint

## Type

Feature

## Description

Implement endpoint to finalize a license upload by attaching uploaded media to the license record and emitting an outbox event.

## Scope

* Attach media to license
* Update license record
* Emit outbox event

## Acceptance Criteria

* [ ] `POST /api/v1/licenses/{id}/finalize` attaches media
* [ ] License remains `pending` after finalize
* [ ] Outbox event is written in same transaction

## Dependencies

* Blocked by: [PF-038], [PF-039], outbox infra
* Blocks: Admin verification, notifications

## Technical Notes

* Tables: `licenses`, `media`, `media_attachments`, `outbox_events`
* **ASSUMPTION:** Worker handles notifications later

## Out of Scope

* Media processing
* Admin actions

---

## [PF-041] Implement list licenses endpoint (active store)

## Type

Feature

## Description

Implement endpoint to list all licenses belonging to the active store.

## Scope

* Fetch licenses by store
* Support basic filtering (status)
* Enforce store-scoped access

## Acceptance Criteria

* [ ] `GET /api/v1/licenses` returns licenses for active store
* [ ] Only authorized roles may access
* [ ] Response includes status and expiration dates

## Dependencies

* Blocked by: [PF-038]
* Blocks: Store compliance UI

## Technical Notes

* Table: `licenses`
* **ASSUMPTION:** Pagination optional for MVP

## Out of Scope

* Cross-store license views

---

## [PF-042] Implement delete license endpoint

## Type

Feature

## Description

Implement endpoint to delete a license belonging to the active store and detach associated media.

## Scope

* Delete license row
* Remove media attachment
* Enforce authorization

## Acceptance Criteria

* [ ] `DELETE /api/v1/licenses/{licenseId}` deletes license
* [ ] Media is detached (not necessarily deleted)
* [ ] Unauthorized access is rejected

## Dependencies

* Blocked by: [PF-041]
* Blocks: License lifecycle completeness

## Technical Notes

* Tables: `licenses`, `media_attachments`
* **ASSUMPTION:** Media GC handled separately

## Out of Scope

* Hard delete of media objects

---

## [PF-043] Implement admin license verify/reject endpoint

## Type

Feature

## Description

Implement admin-only endpoint to verify or reject a license and update its status.

## Scope

* Admin authorization
* Update license status
* Record audit log

## Acceptance Criteria

* [ ] `POST /api/v1/admin/licenses/{licenseId}/verify` updates status
* [ ] Only admin users can access
* [ ] Audit log entry is created

## Dependencies

* Blocked by: Admin auth, audit logging
* Blocks: Store KYC mirroring

## Technical Notes

* Tables: `licenses`, `audit_logs`
* **ASSUMPTION:** Admin UI implemented later

## Out of Scope

* Automation of verification

---

## [PF-044] Mirror license status changes to store KYC status

## Type

Task

## Description

Ensure store `kyc_status` is updated based on license verification outcomes.

## Scope

* Update store on license verify/reject/expire
* Handle multiple licenses per store

## Acceptance Criteria

* [ ] Verified license sets store KYC to `verified`
* [ ] All licenses rejected/expired sets store accordingly
* [ ] Changes are transactional

## Dependencies

* Blocked by: [PF-043]
* Blocks: Buyer/vendor gating

## Technical Notes

* Tables: `licenses`, `stores`
* **ASSUMPTION:** ‚ÄúAt least one verified license = store verified‚Äù

## Out of Scope

* Manual admin overrides

---

## [PF-045] Add license expiry scheduler + compliance notifications

## Type

Task

## Description

Implement a scheduler to handle license expiry checks and generate in-app compliance notifications.

## Scope

* Daily job:

  * notify licenses expiring in 14 days
  * mark expired licenses
* Emit outbox events
* Create notifications

## Acceptance Criteria

* [ ] Scheduler runs daily
* [ ] Expiring licenses trigger notifications
* [ ] Expired licenses update status and store KYC
* [ ] All actions are idempotent

## Dependencies

* Blocked by: Worker infrastructure, notifications
* Blocks: Compliance enforcement

## Technical Notes

* Tables: `licenses`, `notifications`, `outbox_events`
* **ASSUMPTION:** Email notifications added later

## Out of Scope

* SMS/email delivery
* Manual scheduling UI
